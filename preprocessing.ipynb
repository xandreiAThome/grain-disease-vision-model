{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4d3fa97",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aecfb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "\n",
    "# Import your preprocessing utilities\n",
    "from preprocessing import (\n",
    "    create_validation_split,\n",
    "    get_dataset_statistics,\n",
    "    augment_minority_classes,\n",
    "    get_augmentation_pipeline_no_tensor,\n",
    "    load_and_preprocess_image,\n",
    "    CATEGORIES_MAP\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1357d6",
   "metadata": {},
   "source": [
    "# Data Preprocessing for Grain Disease Classification\n",
    "\n",
    "This notebook documents all preprocessing steps applied to the grain dataset.\n",
    "\n",
    "## Preprocessing Steps:\n",
    "1. Validation Split Creation\n",
    "2. Dataset Statistics Analysis\n",
    "3. Image Transformation Pipeline\n",
    "4. Final Dataset Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c261c69",
   "metadata": {},
   "source": [
    "Create Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc037cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating validation splits...\")\n",
    "maize_stats = create_validation_split(\"maize\", val_ratio=0.15, random_state=42)\n",
    "rice_stats = create_validation_split(\"rice\", val_ratio=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691a9b88",
   "metadata": {},
   "source": [
    "Visualize Split Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c211b94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "for idx, (grain, stats) in enumerate([(\"maize\", maize_stats), (\"rice\", rice_stats)]):\n",
    "    if not stats:\n",
    "        continue\n",
    "    \n",
    "    categories = list(stats.keys())\n",
    "    train_counts = [stats[cat]['train'] for cat in categories]\n",
    "    val_counts = [stats[cat]['val'] for cat in categories]\n",
    "    \n",
    "    x = np.arange(len(categories))\n",
    "    width = 0.35\n",
    "    \n",
    "    axes[idx].bar(x - width/2, train_counts, width, label='Train', alpha=0.8)\n",
    "    axes[idx].bar(x + width/2, val_counts, width, label='Validation', alpha=0.8)\n",
    "    \n",
    "    axes[idx].set_xlabel('Category')\n",
    "    axes[idx].set_ylabel('Number of Images')\n",
    "    axes[idx].set_title(f'{grain.upper()} - Train/Validation Split')\n",
    "    axes[idx].set_xticks(x)\n",
    "    axes[idx].set_xticklabels(categories, rotation=45)\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18667daf",
   "metadata": {},
   "source": [
    "Check Class Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077a6e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "for grain in [\"maize\", \"rice\"]:\n",
    "    print(f\"\\n{grain.upper()}:\")\n",
    "    stats = get_dataset_statistics(grain, splits=['train', 'val', 'test'])\n",
    "    \n",
    "    df = pd.DataFrame(stats).fillna(0).astype(int)\n",
    "    print(df)\n",
    "    print(f\"Total: {df.sum().sum()} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a72cd52",
   "metadata": {},
   "source": [
    "Visualize Augmentation Examples\n",
    "- Show original vs augmented images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2d6b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_augmentation_examples(grain_type, category, n_examples=3):\n",
    "    base_path = Path(f\"./dataset/images/{grain_type}/train/{category}\")\n",
    "    images = list(base_path.glob(\"*.png\"))[:n_examples]\n",
    "    \n",
    "    aug_pipeline = get_augmentation_pipeline_no_tensor(split='train', img_size=224)\n",
    "    \n",
    "    fig, axes = plt.subplots(n_examples, 2, figsize=(8, n_examples * 3))\n",
    "    \n",
    "    for i, img_path in enumerate(images):\n",
    "        # Original\n",
    "        img_orig = cv2.imread(str(img_path))\n",
    "        img_orig = cv2.cvtColor(img_orig, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Augmented\n",
    "        img_aug = aug_pipeline(image=img_orig.copy())['image']\n",
    "        \n",
    "        axes[i, 0].imshow(img_orig)\n",
    "        axes[i, 0].set_title(f\"Original - {img_path.name}\")\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        axes[i, 1].imshow(img_aug)\n",
    "        axes[i, 1].set_title(\"Augmented\")\n",
    "        axes[i, 1].axis('off')\n",
    "    \n",
    "    plt.suptitle(f\"{grain_type.upper()} - {category} Augmentation Examples\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "show_augmentation_examples(\"maize\", \"0_NOR\", n_examples=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f78bf51",
   "metadata": {},
   "source": [
    "Final Dataset Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a737ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== FINAL DATASET SUMMARY ===\")\n",
    "for grain in [\"maize\", \"rice\"]:\n",
    "    print(f\"\\n{grain.upper()}:\")\n",
    "    stats = get_dataset_statistics(grain, splits=['train', 'val', 'test'])\n",
    "    \n",
    "    df = pd.DataFrame(stats).fillna(0).astype(int)\n",
    "    df['Total'] = df.sum(axis=1)\n",
    "    print(df)\n",
    "    print(f\"\\nGrand Total: {df['Total'].sum()} images\")\n",
    "    print(f\"Train/Val/Test Ratio: {df.loc[:, 'train'].sum()}:{df.loc[:, 'val'].sum()}:{df.loc[:, 'test'].sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336cef98",
   "metadata": {},
   "source": [
    "## Preprocessing Summary\n",
    "\n",
    "### Decisions Made:\n",
    "1. **Validation Split**: 15% of training data (stratified by class)\n",
    "2. **Image Size**: 224×224 pixels (standard for CNN architectures)\n",
    "3. **Normalization**: ImageNet statistics (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "4. **Augmentation**: Applied to training set only\n",
    "   - Random 90° rotations\n",
    "   - Horizontal/vertical flips\n",
    "   - Brightness/contrast adjustments\n",
    "   - HSV color shifts\n",
    "   - Gaussian noise\n",
    "\n",
    "### Rationale:\n",
    "- **224×224 size**: Compatible with pre-trained models (ResNet, VGG, EfficientNet)\n",
    "- **ImageNet normalization**: Standard practice for transfer learning\n",
    "- **Augmentation choices**: Preserve grain characteristics while introducing variation\n",
    "- **No test augmentation**: Ensures fair evaluation on original data distribution\n",
    "\n",
    "### Next Steps:\n",
    "- Teammates can import `preprocessing.py` functions\n",
    "- Use `get_augmentation_pipeline()` in data loaders\n",
    "- Validation set ready for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367fbb46",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
